{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `datasets` submodule of `xarray_filters` provides data simulation capabilities.\n",
                "\n",
                "We wrap simulation functions from `scikit-learn` with our own code to return more flexible data structures.\n",
                "\n",
                "The goal is to make it easier to generate data for testing `elm`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import xarray_filters.datasets as ds"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that the at import time we are notified which functions from sklearn could not be converted. That is because we restrict ourselves to simulation functions from sklearn that\n",
                "\n",
                "- return a tuple `(X, y)` with a feature matrix `X` and a 1d vector of labels `y`;\n",
                "- can be called with default values alone\n",
                "\n",
                "That is to keep a section of code simple. Making our solution more general to address the two points above would be an unnecessary distraction at this stage.\n",
                "\n",
                "Note:\n",
                "\n",
                "- We can check that a function can be called with default values alone before we call the function. The warnings above are for the functions that fail that requirement.\n",
                "- However, we cannot check that a function returns the features/labels pair `(X, y)` without calling the function (not in Python). We will find those additional problematic functions in a [later section](#sec-okfuncs)(again, can be fixed, but it's a distraction now)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Showcasing the design and functionality"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### A drop-in replacement of scikit-learn functionality"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The `datasets` library was designed to provide drop-in replacements for the `sklearn.datasets.make_*` functions. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sklearn.datasets as skd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "skd.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0)  # sklearn function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                       astype='array')                                           # new args"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "help(ds.make_classification)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "help(skd.make_classification)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### An extension of scikit-learn functionality"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We also provide postprocessing functionality on top of the `scikit-learn` routines via additional keywords (`astype` and `feature_shape` below)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                       astype='array')                                           # new args"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can also convert to `xarray.Dataset` (or other types, like `pandas.DataFrame`)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dst = ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                            astype='dataset')                                          # new args\n",
                "dst"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dst.y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dst = ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                             astype='dataset', dims=('horizontal','vertical'), shape=(4,5))            # new args\n",
                "dst"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dst.y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dst = ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                             astype='dataset', dims=('horizontal','vertical'), shape=(4,5),\n",
                "                             coords=(list('abcd'), list('efghi')),\n",
                "                             layers=['feat_{:d}'.format(n) for n in range(4)],\n",
                "                             yname='LABEL', attrs={'metadata1': 'super important'})  \n",
                "dst"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dst.LABEL"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Which simulation functions can be used right now?\n",
                "<a id='sec-okfuncs'></a>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds_make_funcs = [f for f in dir(ds) if f.startswith('make_')]  # all make_* functions in xarray_filters/datasets.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "All of the functions above work with defaults only.\n",
                "\n",
                "But some of them do not return a tuple `(X, y)` where X is a feature matrix and y is a 1d vector of labels.\n",
                "\n",
                "We will find which ones now (see the `bad` list below)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "good = []  # to store the make_* functions that return a features/labels pair (X, y)\n",
                "bad = []   # to store the make_* functions that do _not_ return a features/labels pair (X, y)\n",
                "\n",
                "for f in ds_make_funcs:\n",
                "    try:\n",
                "        simdata = ds.__getattribute__(f)(astype='array')\n",
                "    except ValueError as e:\n",
                "        print('ERROR: {}'.format(str(e)))\n",
                "        bad.append(f)\n",
                "    else:\n",
                "        good.append(f)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can see the problematic functions in the error messages above. Also listed here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "bad"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "And here are the functions we can use without a problem with the current implementation.\n",
                "\n",
                "Again, we can make it more general, but I'd recommend doing that after we pin down the whole API and tests for the functions that work with the simpler code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "good"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Implementation details\n",
                "\n",
                "The central functionality here is implemented in the following two objects:\n",
                "\n",
                "- The `NpXyTransformer` class that has multiple `to_*` methods (`to_dataset`, `to_dataframe`, `to_array`, etc.). Adding different postprocessing routines can be done by adding a new `NpXyTransformer.to_*` method with the appropriate code and documentation.\n",
                "- A `_make_base` function that takes as input a `sklearn.datasets._make_*` function (like `make_classification`) and creates a new \"version\" of it under the `datasets` namespace, with useful signature, docs and extended functionality.\n",
                "\n",
                "It's easier to see with an example. Let's construct the same data with the \"direct\" approach (using the keyword `astype` inside the `make_*` function) and the step-by-step approach (which is what the direct approach does under the hood)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X1, y1 = ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                                astype='array')                                           # new args    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "Xyt = ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0,  # sklearn args\n",
                "                             astype=None)\n",
                "X2, y2 = Xyt.to_array()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "np.allclose(X1, X2)  # floating-point data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.alltrue(y1 == y2)  # integer data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "help(ds.NpXyTransformer.astype)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds.NpXyTransformer.astype??"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "help(ds.NpXyTransformer.to_array)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This design allows us to implement any data transformations we want by just creating new `to_*` methods under `NpXyTransformer`, while still enjoying:\n",
                "\n",
                "- All the work (code and docs) done in sklearn\n",
                "- Argument checking, docs for each transformation in its own method, easier to inspect than `**kwargs` with lots of `if/else` checks."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For recap, here is the full \"low-level path\" to a new `make_classification` function and using it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "my_classification = ds._make_base(skd.make_classification)\n",
                "Xyt = my_classification(n_samples=20, n_features=4, n_classes=2, random_state=0, astype=None)\n",
                "X, y = Xyt.to_array()\n",
                "X, y\n",
                "\n",
                "# same as\n",
                "# ds.make_classification(n_samples=20, n_features=4, n_classes=2, random_state=0, astype='array')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "help(my_classification)  # signature/docstring build automatically"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}