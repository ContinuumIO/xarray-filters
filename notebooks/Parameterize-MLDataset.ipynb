{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline outside of ML\n",
    "\n",
    "This notebook shows some trial and error to create a `Pipeline` that can be used with `xarray_filters`.  \n",
    "\n",
    "This is a continuation of goals in [Elm issue #149](https://github.com/ContinuumIO/elm/issues/149) to separate ML from GIS utils."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to be able to run something like this:\n",
    "```\n",
    "from xarray_filters.pipeline import Pipeline\n",
    "from xarary_filters.steps import Generic, Serialize\n",
    "def step_1(dset, **kw):\n",
    "    return kw['a'] * dset.mean(dim=('x', 'y')) ** kw['b']\n",
    "\n",
    "def step_2(dset, **kw):\n",
    "    return kw['a'] + dset * kw['b']\n",
    "    \n",
    "steps = (('s1', Generic(step_1)),\n",
    "         ('s2', Generic(step_2)),\n",
    "         ('s3', Serialize('two_step_pipeline_out.nc')))\n",
    "pipe = Pipeline(steps=steps)\n",
    "pipe.set_params(s1__a=2,\n",
    "                s1__b=3,\n",
    "                s2__a=0,\n",
    "                s2__b=0,\n",
    "                s3__fname='file_with_zeros.nc')\n",
    "pipe.fit_transform(X)\n",
    "```\n",
    " * The example above uses scikit-learn `set_params` style of setting parameters where:\n",
    "   * Steps in the `Pipeline` are named, `s1`, `s2`, and `s3` in this case\n",
    "   * Double underscore notation is used to pass parameters to the `set_params` method of a given step.  Here:\n",
    "     * `a` and `b` are parameters accepted by `step_1` and `step_2`\n",
    "     * `fname` is accepted by `Serialize`\n",
    "   * The `Dataset` or `MLDataset` `X` is run through the 3 steps\n",
    "   * Note the import statements with `xarray_filters` at top of snippet is what we need to do based on this notebook\n",
    "* Classes formerly part of `elm.pipeline.steps` will now inherit from `sklearn.base.BaseEstimator`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarray_filters import MLDataset\n",
    "from xarray_filters.tests.test_data import new_test_dataset\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline as _Pipeline\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "import six\n",
    "\n",
    "from xarray_filters.pipeline import Step, WriteNetCDF, Generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_test_dataset(('wind', 'pressure', 'temperature',))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_1(dset, **kw):\n",
    "    return kw['a'] * dset.mean(dim=('x', 'y')) ** kw['b']\n",
    "\n",
    "def step_2(dset, **kw):\n",
    "    return kw['a'] + dset * kw['b']\n",
    "\n",
    "steps = (('s1', Generic(step_1)),\n",
    "         ('s2', Generic(step_2)),\n",
    "         ('s3', WriteNetCDF('two_step_pipeline_out.nc')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, s1), _, (_, s3) = steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.set_params(kw=dict(a=0, b=0))\n",
    "ones = s1.transform(X)\n",
    "s1.set_params(kw=dict(a=2, b=2))\n",
    "other = s1.transform(X)\n",
    "other.temperature - ones.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example(Generic):\n",
    "    a = 1\n",
    "    b = 2\n",
    "    func = None\n",
    "s1, s2 = Example(func=step_1), Example(func=step_2)\n",
    "steps = ('s1', s1), ('s2', s2), ('s3', s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.set_params(a=2,b=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elm.pipeline import Pipeline\n",
    "Pipeline._validate_steps = lambda x: True\n",
    "pipe = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(s1__a=2, s1__b=3, s2__a=0, s2__b=0, s3__fname='file_with_zeros.nc')\n",
    "pipe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_params(s1__a=2, s1__b=3, s2__a=1, s2__b=1, s3__fname='file_nonzero.nc')\n",
    "pipe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -l *.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarray_filters.datasets import make_regression\n",
    "from xarray_filters.pipeline import Generic\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.svm import SVR\n",
    "from elm.pipeline import steps\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from xarray_filters import MLDataset\n",
    "from xarray_filters.datasets import _make_base\n",
    "from elm.model_selection.ea_searchcv import EaSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (30, 33)\n",
    "X = make_regression(shape=shape, n_samples=np.prod(shape), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa, ya = X.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa, ya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elm.pipeline.steps import LinearRegression, PolynomialFeatures, PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elm.pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('poly', PolynomialFeatures()), ('pca', PCA()), ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
