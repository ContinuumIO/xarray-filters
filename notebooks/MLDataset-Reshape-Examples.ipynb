{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLDataset - Examples with Reshaping and Chaining Methods\n",
    "\n",
    "`xarray_filters.MLDataset` is a subclass of `xarray.Dataset` with methods for reshaping the `Dataset`'s `DataArray`s from time series, rasters, or N-D arrays into a single 2-D `DataArray` for input to statistical models.  \n",
    "\n",
    "The notebook works with the following methods of `MLDataset`s:\n",
    "\n",
    " * `MLDataset.to_features`: convert `DataArray`s of a `MLDataset` to a single 2-D `DataArray` by calling `.ravel()` on each `DataArray` (i.e. each `DataArray` to a single column)\n",
    " * `MLDataset.from_features`: convert a `MLDataset` with a single 2-D `DataArray` back to the original separate time series, rasters, or N-D arrays\n",
    " * `MLDataset.chain`: Calling `MLDataset.pipe` (`xarray.Dataset.pipe`) repeatedly for a `Sequence` of items that may be:\n",
    "   * a callable\n",
    "   * a `Sequence` composed of a callable followed by positional arguments and keyword arguments\n",
    "   * a `Sequence` of a string (assumed to be a `DataArray` method, e.g. `DataArray.quantile`) followed by positional arguments and keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from xarray_filters import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell imports a function to create example `xarray_filters.MLDataset` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xarray_filters.tests.test_data import new_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = new_test_dataset(layers=('temperature', 'pressure', 'wind_x', 'wind_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods of `MLDataset` that are not methods of `xarray.Dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(dir(MLDataset)) - set(dir(xr.Dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MLDataset` works like an `xarray.Dataset`.  The following is converting 4-D arrays to 2-D arrays by taking the mean over the `z` and `t` dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means_raster = X.mean(dim=('z', 't'))\n",
    "X_means_raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xarray_filters.MLDataset.to_features`\n",
    "`to_features()` below converts each 4-D array of `X` to a column and concatenates the columns into a single `DataArray`.  See optional arguments to `to_features` for controlling the name of the 2-D `DataArray` (`features_layer='features'` by default) and the row and column dimension names (`(space, layer)` by default).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = X.to_features()\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `features` `DataArray` preserves the original coordinates of the 4-D arrays by creating a `pandas.MultiIndex`.  This allows calling `from_features` later to reshape into the 4-D array shapes, even if rows from the `features` `DataArray` are dropped, e.g. as in the case of dropping rows with `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the `features` `DataArray` are named by the `layer` that was flattened from 4-D to a 1-D column.  Usage of `OrderedDict` throughout `MLDataset` internals ensures that the `layers` (`DataArray`s) always iterate into the same column order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the first few `(x, y, z, t)` coordinates of the `pandas.MultiIndex` `space`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.space.indexes['space'].tolist()[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.space.indexes['space'].names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is also possible to transpose the `layers` before calling `.ravel()` on each one (the usage of the `trans_dims` keyword to `to_features()`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2 = X.mean(dim='x').to_features(trans_dims=('t', 'z', 'y'))\n",
    "example2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `data_vars_func` decorator\n",
    "The `data_vars_func` decorator allows writing a function that takes named `layers` as keywords or positional arguments.  In the example below, it is assumed that the decorated `magnitude` function will be passed to `X.chain` in situations where `X` has `layers` named `wind_x`, `wind_y`.  All other `data_vars` keys/values are passed as `other_data_vars` keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@data_vars_func\n",
    "def magnitude(wind_x, wind_y, **other_data_vars):\n",
    "    a2 = wind_x ** 2\n",
    "    b2 = wind_y ** 2\n",
    "    mag = (a2 + b2) ** 0.5\n",
    "    return dict(magnitude=mag)\n",
    "X.chain(magnitude, layers=['wind_x', 'wind_y']).to_features(features_layer='magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `for_each_array` decorator\n",
    "`for_each_array` allows automates calling a function that takes a `DataArray` argument and returns a `DataArray` for each `DataArray` (`layer`) in a `MLDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@for_each_array\n",
    "def plus_one(arr, **kw):\n",
    "    return arr + 1\n",
    "\n",
    "@for_each_array\n",
    "def minus_one(arr, **kw):\n",
    "    return arr - 1\n",
    "\n",
    "\n",
    "plus = X.chain(plus_one)\n",
    "minus = X.chain(minus_one)\n",
    "\n",
    "assert np.all(plus.wind_x - minus.wind_x == 2.)\n",
    "assert np.all(plus.temperature - minus.temperature == 2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@for_each_array\n",
    "def transform_example(arr, **kw):\n",
    "    up = arr.quantile(0.75, dim='z')\n",
    "    low = arr.quantile(0.25, dim='z')\n",
    "    median = arr.quantile(0.5, dim='z')\n",
    "    return (arr - median) / (up - low)\n",
    "\n",
    "X.chain(transform_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@for_each_array\n",
    "def agg_example(arr, **kw):\n",
    "    return arr.mean(dim='t').quantile(0.25, dim='z')\n",
    "\n",
    "aggregated = X.chain((transform_example, agg_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `data_vars_func` decorated functions, anything `dict`-like, an `MLDataset` or `xarray.Dataset` may be returned and it will be converted to `MLDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "@data_vars_func\n",
    "def f(wind_x, wind_y, temperature, pressure):\n",
    "    mag = (wind_x ** 2 + wind_y ** 2) ** 0.5\n",
    "    return OrderedDict([('mag', mag), ('temperature', temperature), ('pressure', pressure)])\n",
    "\n",
    "f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = f(X).to_features()\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat.features.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `xarray_filters.MLDataset.chain`\n",
    "\n",
    "`.chain` can be called on an `MLDataset` to run callables in sequence, passing an `MLDataset` between steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@for_each_array\n",
    "def agg_x(arr, **kw):\n",
    "    return arr.mean(dim='x')\n",
    "\n",
    "@for_each_array\n",
    "def agg_y(arr, **kw):\n",
    "    return arr.mean(dim='y')\n",
    "\n",
    "@for_each_array\n",
    "def agg_z(arr, **kw):\n",
    "    return arr.mean(dim='z')\n",
    "\n",
    "\n",
    "time_series = X.chain((agg_x, agg_y, agg_z))\n",
    "time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_features().features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(time_series.to_features().from_features().temperature == time_series.temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating some synthetic rasters in `MLDataset` that are similar to LANDSAT imagery with 8 spectral bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['band_{}'.format(idx) for idx in range(1, 9)]\n",
    "shape = (200, 200)\n",
    "rand_np_arr = lambda: np.random.normal(0, 1, shape)\n",
    "coords = [('x', np.arange(shape[0])), ('y', np.arange(shape[1]))]\n",
    "rand_data_arr = lambda: xr.DataArray(rand_np_arr(), coords=coords, dims=('x', 'y'))\n",
    "data_vars = OrderedDict([(layer, rand_data_arr()) for layer in layers])\n",
    "dset = MLDataset(data_vars)\n",
    "dset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of chaining callables that use `for_each_array` and `data_vars_func` as decorators, where the example functions also show the variety of return data types allowed in functions decorated by `data_vars_func`.\n",
    "\n",
    "Note the `keep_arrays=True` keyword argument in the function prototypes - this means that the original `layers` passed into the decorated functions will be part of the `MLDataset` outputs, even if the decorated functions do not return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "@for_each_array\n",
    "def standardize(arr, dim=None, **kw):\n",
    "    mean = arr.mean(dim=dim)\n",
    "    std = arr.std(dim=dim)\n",
    "    return (arr - mean) / std\n",
    "\n",
    "@data_vars_func\n",
    "def ndvi(band_5, band_4, keep_arrays=True):\n",
    "    return OrderedDict([('ndvi', (band_5 - band_4) / (band_5 + band_4))])\n",
    "\n",
    "\n",
    "@data_vars_func\n",
    "def ndwi(band_3, band_5, keep_arrays=True, **kw):\n",
    "    return {'ndwi': (band_3 - band_5) / (band_3 + band_5)}\n",
    "\n",
    "\n",
    "@data_vars_func\n",
    "def mndwi_36(band_3, band_6, keep_arrays=True):\n",
    "    return xr.Dataset({'mndwi_36': (band_3 - band_6) / (band_3 + band_6)})\n",
    "\n",
    "\n",
    "@data_vars_func\n",
    "def mndwi_37(band_3, band_7, keep_arrays=True):\n",
    "    return MLDataset(OrderedDict([('mndwi_37', (band_3 - band_7) / (band_3 + band_7))]))\n",
    "\n",
    "normed_diffs = dset.chain((ndvi, ndwi, mndwi_36, mndwi_37))\n",
    "standardized = dset.chain(partial(standardize, dim='x'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging two `MLDataset`s and converting the merged output to a features 2-D `DataArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catted = normed_diffs.merge(standardized, overwrite_vars=standardized.data_vars.keys())\n",
    "catted = catted.to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catted.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catted.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catted.from_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following synthetic data example shows the logic above in this notebook can work for any number of dimensions, e.g. the 6-D `DataArray`s below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = (2, 3, 4, 5, 6, 7)\n",
    "dims = ('a', 'b', 'c', 'd', 'e', 'f')\n",
    "coords = OrderedDict([(dim, np.arange(s)) for s, dim in zip(shp, dims)])\n",
    "dset = MLDataset(OrderedDict([('layer_{}'.format(idx), \n",
    "                               xr.DataArray(np.random.normal(0, 10, shp),\n",
    "                                            coords=coords,\n",
    "                                            dims=dims)) \n",
    "                              for idx in range(6)]))\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.layer_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 6-D `DataArray`s, calling `to_features` creates a `pandas.MultiIndex` with 6 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.to_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells demonstrate `MLDataset.chain` is the same as calling `.pipe` several times in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@for_each_array\n",
    "def example_agg(arr, dim=None):\n",
    "    return arr.std(dim=dim)\n",
    "\n",
    "@data_vars_func\n",
    "def layers_example_with_kw(**kw):\n",
    "    new = OrderedDict([('new_layer_100', kw['layer_3'] + kw['layer_4'])])\n",
    "    new.update(kw)\n",
    "    return MLDataset(new)\n",
    "\n",
    "@data_vars_func\n",
    "def layers_example_named_args(layer_1, layer_2, new_layer_100):\n",
    "    return MLDataset(OrderedDict([('final', new_layer_100 / (layer_1 + layer_2))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.pipe(example_agg, dim='a'\n",
    "         ).pipe(example_agg, dim='b'\n",
    "               ).pipe(layers_example_with_kw\n",
    "                     ).pipe(layers_example_named_args).to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.chain([(example_agg, dict(dim='a')),\n",
    "             (example_agg, dict(dim='b')),\n",
    "             layers_example_with_kw,\n",
    "             layers_example_named_args,\n",
    "            ]).to_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
